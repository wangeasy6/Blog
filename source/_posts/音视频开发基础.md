---
title: 音视频开发基础
date: 2024-05-07 22:00:00
toc: true
categories:
  - Technology
tags:
  - 音视频
---

<img src="/resources/Cover/media.jpg" height=400 />

之前做的4份工作中3份都与音视频相关，于是整理了一下音视频开发相关的基础概念和知识点，作为回顾和链接。

<!--more-->

<br/>

# 相关产品

### 电视机顶盒

数字视频变换盒（Set Top Box）简称STB，通常称作机顶盒或机上盒，是一个连接电视机与外部信号源的设备。信号可以来自有线电缆、卫星天线、宽带网络以及地面广播。

### IPC

全称 IP Camera，即网络摄像机，由网络编码模块和模拟摄像机组合而成。网络编码模块将模拟摄像机采集到的模拟视频信号编码压缩成数字信号，从而可以直接接入网络交换及路由设备。

### NVR

全称 Network Video Recorder，即网络视频录像机，是网络视频监控系统的存储转发部分，NVR与视频编码器或网络摄像机协同工作，完成视频的录像、存储及转发功能。

### AI Camera

AI 摄像头，即以实现 AI 视觉应用为主要目的的摄像头。如 安防监控、面部识别、自动驾驶、运动跟踪 等场景。

<br/>

# 摄像头

一个摄像头一般由 Sensor、镜头、外围电路、输出接口 这 4 个部分组成。

## Image Sensor

摄像头传感器是摄像头模块的核心组件，负责捕捉光线并将其转换为电信号，进而生成图像。以下是摄像头传感器的一些基本概念和关键特性：

1. **类型**：摄像头传感器主要分为两种类型，电荷耦合器件（Charge-Coupled Device, CCD）和互补金属氧化物半导体（Complementary Metal-Oxide-Semiconductor, CMOS）。CCD传感器在图像质量上通常更优，但成本较高且能耗大；CMOS传感器则在成本和能耗上更有优势，是目前大多数摄像头中使用的类型。
2. **分辨率**：分辨率是指传感器能够捕捉的像素数量，通常以水平×垂直像素表示，如1920×1080，表示为200万像素。分辨率越高，图像的细节越丰富。
3. **尺寸**：传感器的物理尺寸影响其捕捉光线的能力，一般来说，传感器尺寸越大，单个像素的面积越大，越能在低光照条件下捕捉到更多的光线，从而提高图像质量。
4. **像素尺寸**：单个像素的尺寸对于图像质量同样至关重要。较大的像素尺寸通常意味着更好的光线收集能力和更低的噪声水平。
5. **感光度（ISO）**：感光度是指传感器对光线的敏感程度。较高的ISO值可以在低光照条件下捕捉图像，但同时也可能增加图像的噪声。
6. **动态范围**：动态范围是指传感器能够捕捉的从最暗到最亮的细节的范围。高动态范围（HDR）能够更好地处理高对比度的场景。
7. **色彩滤镜阵列**：大多数传感器使用色彩滤镜阵列（Color Filter Array, CFA）来捕捉彩色图像。最常用的是拜耳（Bayer）阵列，2×2的方块中绿色2个，红色蓝色各一个。（由于滤光会带来亮度上的损失，有种MONO sensor，没有滤光片的处理，亮度会大大提高（有文章说可以提高四倍），但是这就感知不到颜色了，所以又叫黑白sensor。）
8. **光谱响应曲线**：描述摄像头传感器中的单个像素对不同波长光（从紫外到红外）的响应特性的图表。
9. **全局快门与滚动快门**：全局快门传感器能同时曝光所有像素，而滚动快门则是逐行或逐区域曝光。全局快门更适合捕捉快速运动的物体，因为它可以减少运动模糊和畸变。
10. **光学防抖（OIS）**：一些摄像头传感器配备有光学稳定功能，通过物理移动传感器来补偿手抖或其他形式的相机移动，从而提高图像稳定性。
11. **深度传感器**：除了常规的RGB传感器外，一些摄像头还配备有深度传感器，能够测量物体的距离，常用于3D成像、增强现实（AR）和自动对焦。
12. **快门**：是摄像头中控制光线照射到传感器上时间的机制。分为机械快门和电子快门，快门速度指的是快门开启和关闭之间的时间间隔，通常以秒或分数秒表示（如1/60秒、1/1000秒）。快门速度越快，进入的光线越少，曝光时间越短。

## 镜头

镜头是摄像头系统中用于聚焦光线以形成图像的关键光学组件。以下是镜头的一些基本概念和特性：

1. **焦距**：焦距是镜头和成像传感器之间的距离，在该距离下，无限远处的物体能够清晰成像。它通常以毫米（mm）为单位，决定了视角的宽窄和放大倍数的大小。
2. **光圈**：光圈是镜头内用来控制通过镜头到达传感器的光线量的开口。光圈的大小用 f-stop（f值）表示，如f/2.8、f/4等，f值越小，光圈越大，允许更多光线进入。
3. **视角**：视角是指镜头能够覆盖的场景范围。广角镜头提供宽广的视角，适合风景摄影；而长焦镜头提供狭窄的视角，适合拍摄远处的物体。
4. **对焦方式**：镜头可以通过手动对焦或自动对焦（AF）来调整焦点。自动对焦系统可以进一步分为多种类型，如相位检测AF、对比度检测AF等。
5. **光学防抖（OIS）**：一些镜头内置光学稳定系统，可以减少因手抖或其他相机移动引起的图像模糊。
6. **镜头畸变**：由于镜头的光学特性，图像可能会出现畸变，如桶形畸变（图像边缘向外弯曲）和枕形畸变（图像边缘向内弯曲）。
7. **镜头涂层**：现代镜头通常具有特殊的涂层，用于减少镜头表面反射，增加透光率，提高图像质量和减少耀斑和鬼影。
8. **镜头结构**：镜头由多个透镜元件组成，每个元件都有助于改善图像质量。镜头结构的复杂性通常与镜头的性能和成本成正比。
9. **定焦与变焦**：定焦镜头具有固定焦距，而变焦镜头允许在一定范围内调整焦距，提供更大的拍摄灵活性。
10. **微距镜头**：微距镜头专门设计用于拍摄极小物体的细节，能够实现极高的放大比例。
11. **鱼眼镜头**：鱼眼镜头提供极宽的视角，通常超过180度，能够产生独特的视觉效果。
12. **镜头卡口**：不同的相机品牌（如佳能、尼康、索尼等）可能使用不同的镜头卡口，镜头的选择需要考虑与相机的兼容性。

## 输出接口

此处的接口一般是摄像机和主机处理器之间的接口，从摄像头输出，输入到主机。

### DVP

DVP（Digital Video Port）接口是一种数字视频接口标准，旨在传输和接收数字视频数据。它是一种相对简单和经济实惠的接口，广泛应用于低成本摄像头和一些消费电子产品中。DVP接口通常使用多个并行数据线来传输视频和控制信号，其中每个线路都负责传输特定的数据位。这种并行传输的方式可以实现较高的带宽和较低的延迟，适用于对实时性要求较高的应用场景。

DVP 接口使用的是LVDS（Low Voltage Differential Signaling）电气接口标准。LVDS（Low-Voltage Differential Signaling）低电压差分信号，是一种低功耗、低误码率、低串扰和低辐射的差分信号技术，这种传输技术可以达到155Mbps以上，LVDS技术的核心是采用极低的电压摆幅高速差动传输数据，可以实现点对点或一点对多点的连接，其传输介质可以是铜质的PCB连线，也可以是平衡电缆。

由于其成本较低，dvp接口在一些价格敏感的市场上得到了广泛应用。

### [MIPI](https://www.mipi.org/)

移动行业处理器接口（Mobile Industry Processor Interface），是MIPI联盟发起的为移动应用处理器制定的开放标准。MIPI 标准将手机内部的接口如摄像头、显示屏接口、射频/基带接口等标准化，从而减少手机设计的复杂程度和增加设计灵活性。

目前比较重要的接口有 **DSI（Display Serial Interface）**和 **CSI（Camera Serial Interface）**。MIPI CSI-2是移动和其他市场中使用最广泛的相机接口。它因其易用性和支持范围广泛的高性能应用(包括1080p、4K、8K及更高的视频)和高分辨率摄影而获得广泛采用。

MIPI CSI-2可以在MIPI Alliance的两个物理层中的任何一个上实施：MIPI C-PHY v2.0或 MIPI D-PHY v2.5。当前应用较广的物理层实现**D-PHY**居多。

MIPI 接口则采用了更先进的低电压差分信号传输技术。

D-PHY 接口一般是1/2/4 Lane，每个 Lane 走差分线对，是电流驱动型，单信号幅度一般是200mv，线对差分的幅度在400mv左右，布线要求是等长且成双成对，D-PHY是有单独的同步时钟来进行同步，最多是10根线，但解码接收要容易些；

D-PHY的物理层支持 HS(High Speed)和 LP(Low Power)两种工作模式。HS 模式：低压查分信号、功耗大、高速率（80M -1Gbps）、信号幅值（100mv-300mv）。LP 模式：单端信号、功耗小、速率低（< 10Mbps) 、信号幅值（0-1.2V）。

MIPI 接口具有较小的尺寸、较高的带宽和较低的功耗，它可以满足手机摄像头对于小尺寸、高画质和高帧率的要求。此外，mipi接口还支持一些高级功能，例如相位对焦、HDR（High Dynamic Range）和实时视频传输等。

### HiSPi

为了支持更高带宽的传感器，Aptina Imaging推出了一款高速串行接口，称为HiSPi。 HiSPi接口可在1到4个通道工作，传输串行数据，外加一条时钟线。每个信号都是差分的，运行速度高达700 Mbps。为了使用传统的并行总线与ISP连接，莱迪思创建了HiSPi与并行格式接口的桥接。

# 音视频接口

## 视频输出

### VGA

视频图形阵列（Video Graphics Array）是IBM于1987年提出的一个使用模拟信号的电脑显示标准（也被称为D-Sub接口）。VGA接口共有15针，分成3排，每排5个孔。 其中，除了2根NC（Not Connect)、3根显示数据总线和5个GND，比较重要的是3根RGB彩色分量信号和2根扫描同步信号 HSYNC 和 VSYNC 针。VGA接口中彩色分量采用RS343电平标准，峰值电压为1V。

### DVI

数字视频接口（Digital Visual Interface）。是一种视频接口标准，设计的目的是用来传输未经压缩的数字化视频。广泛应用于LCD、数字投影机等显示设备上。此标准由显示业界数家领导厂商所组成 数字显示工作小组（Digital Display Working Group，DDWG）制订。DVI接口可以发送未压缩的数字视频数据到显示设备。本规格部分兼容于HDMI标准。

### HDMI

高清多媒体接口（High Definition Multimedia Interface）是一种全数字化视频和声音发送接口，可以发送未压缩的音频及视频信号。HDMI可用于机顶盒、DVD播放机、个人计算机、电视、游戏主机、综合扩大机、数字音响与电视机等设备。HDMI可以同时发送音频和视频信号，由于音频和视频信号采用同一条线材，大大简化系统线路的安装难度。

### DP

DisplayPort（简称DP）是一个由PC及芯片制造商联盟开发，视频电子标准协会（VESA）标准化的数字式视频接口标准。该接口免认证、免授权金，主要用于视频源与显示器等设备的连接，并也支持携带音频、USB和其他形式的数据。

此接口的设计是为取代传统的VGA、DVI和FPD-Link（LVDS）接口。通过主动或被动适配器，该接口可与传统接口（如HDMI和DVI）向后兼容。

### BT656/BT1120

BT.656和BT.1120都是由国际电信联盟（ITU）制定的视频传输标准，用于在专业视频设备之间传输数字视频信号。

BT.656 定义了一个并行的硬件接口用来传送一路 4:2:2 的ycbcr的数字视频流。该硬件接口由8根数据信号和1根时钟信号组成。

BT.1120针对的则是1080P分辨率的高清模拟视频的数字化传输规范。BT1120规范中定义一个图像帧应该包含1125总行数和1080有效行，而每行的有效像素则为1920个像素，并且能够支持逐行和隔行的24Hz、25Hz、30Hz、50Hz、60Hz等扫描频率。

## 音频接口

### mic in

即麦克风输入，是连接麦克风录音使用的。

这个端口和 Line in的区别在于它有前置放大器，换言之麦克风本身输出功率小，因此必须要有一个外部的放大设备来放大音频信号。

### line in

即线性输入。该端口主要用于连接电吉他、电子琴、合成器等外界设备的音频信号输出的录音，由于这些设备本身输出功率就比较大，因此需要连接到 Line in 端口录音，当然使用它们录音从某种程度上也可以被称为外部设备的 “内录”。一般使用的声卡越好，Line in里的噪音就会越低，录制效果也会比较好。

### line out

用来输出未经放大芯片放大的模拟音频信号，一般连接耳机。

### I2S

I2S(Inter—IC Sound)总线, 又称集成电路内置音频总线，是飞利浦公司为数字音频设备之间的音频数据传输而制定的一种总线标准。

标准的I2S总线电缆是由3根串行导线组成的：1根是时分多路复用（简称TDM）数据线；1根是字选择线；1根是时钟线。

# 音视频处理

## ISP

图像信号处理（Image Signal Processing）。主要用来对前端图像传感器输出信号处理的单元，以匹配不同厂商的图像传感器。

**3A**：

* **AWB**：自动白平衡（Auto White Balance）
* **AE**：自动曝光（Auto Exposure）
* **AF**：自动聚焦（Auto Focus）

**ISOSpeedRatings**：ISO速率

**ExposureTime**：曝光时间

**ExposureBiasValue**：曝光补偿

**ExposureMode**：曝光模式

**MaxApertureValue**：最大光圈值

**WhiteBalance**：白平衡

**DigitalZoomRatio**：数字缩放比例

**Gain**：增益

**WDR**：宽动态范围（Wide dynamic range）

**LDC**：镜头畸变校正（Lens distortion correction）

**LCAC**：镜头色差校准（Lens Chromatic Aberration Calibration）

**CCM**：色彩校正矩阵（Color Correction Matrix）

**Gamma**：主要是对亮度有影响

**DRC**：动态范围控制

**CSC**：色彩空间转换（Color Space Conversation）

* **Saturation**：饱和度
* **Contrast**：对比度
* **Luminance**：亮度
* **Sharpness**：锐度/清晰度
* **Hue**：色调/色度

**Dehaze**：图像去雾

**LDCI**：局部对比度增强

**HLC**：强光抑制（High Light Compensation）

**BLC**：背光补偿（Back Light Compensation）

## 音频

**AEC**：回声消除（Acoustic Echo Cancel）

**ANR**：背景噪声抑制（Automatic Noise Suppression）

**AGC**：自动增益控制（Automatic Gain Control）

# 编码

## 图像编码

### YUV

YUV，是一种颜色编码方法。常使用在各个视频处理组件中。 YUV在对照片或视频编码时，考虑到人类的感知能力，允许降低色度的带宽。由于色度信号的减少，YUYV格式在存储和传输视频数据时比未压缩的RGB格式更高效。

YUV 是编译 true-color 颜色空间（color space）的种类，Y'UV, YUV, YCbCr，YPbPr等专有名词都可以称为YUV，彼此有重叠。

“Y”表示明亮度（Luminance或Luma），也就是灰阶值，“U”和“V”表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。

常见的YUV格式：YUV422、YUV444、YUV411、YUV420、YUV410、YUY2、YUYV、YVYU、UYVY、AYUV、Y41P、Y411、Y211、IF09、IYUV、YV12、YVU9、YUV411、YUV420、NV12、NV21。

简介如下：

1. **YUV 4:4:4**：每个Y分量都有自己的U和V分量，不进行色度子采样，因此色彩最丰富但数据量也最大。
2. **YUV 4:2:2**：每两个Y分量共享一组U和V分量，色度水平方向减半，常见的格式包括YUYV、UYVY、YVYU等。
3. **YUV 4:2:0**：每四个Y分量共享一组U和V分量，色度水平和垂直方向都减半，常见的格式包括I420、YV12、NV12、NV21等。
4. **I420（YUV 4:2:0 Planar）**：Y分量单独存放，UV分量交错存放，具体是先连续存放所有Y分量，然后是U分量，最后是V分量1。
5. **YV12**：与I420类似，但U和V分量的顺序相反。
6. **NV12**：Y分量单独存放，UV分量交错存放，但顺序是U在V之前。
7. **NV21**：与NV12类似，但V在U之前。
8. **YUYV**：属于YUV 4:2:2 Packed格式，Y0U0Y1V1...的顺序排列。
9. **UYVY**：也属于YUV 4:2:2 Packed格式，但顺序是U0Y0V0Y1...
10. **YUV 422P**：属于YUV 4:2:2 Planar格式，先存储所有Y分量，然后是U分量，最后是V分量。

### RGB

RGB是一种常见的颜色编码格式，它采用红、绿、蓝三种颜色组成图像。RGB的R、G、B三个分量分别表示红色、绿色和蓝色的强度。RGB图像中的每个像素都需要三个值来表示颜色，因此它的数据排列方式是按照红、绿、蓝的顺序排列。

常见的RGB格式：

1. **RGB24**：这是最简单的RGB格式，每个颜色通道使用8位，总共24位来表示一个像素。红、绿、蓝的顺序排列。
2. **RGBA32**：在RGB24的基础上增加了一个8位的Alpha通道，用于透明度。
3. **ARGB32**：与RGBA32类似，但Alpha通道在最前面。
4. **BGR24**：与RGB24类似，但颜色通道的顺序是蓝、绿、红。
5. **BGRA32**：与BGR24类似，但增加了Alpha通道。
6. **XRGB32**：与RGB24类似，但增加了一个未使用的位（通常设置为0）。
7. **XBGR32**：与XRGB32类似，但颜色通道的顺序是蓝、绿、红。
8. **RGB565**：这是一种压缩的RGB格式，每个颜色通道使用5位表示红色和绿色，6位表示蓝色，总共16位。
9. **BGR565**：与RGB565类似，但颜色通道的顺序是蓝、绿、红。
10. **RGB555**：每个颜色通道使用5位表示，剩下1位不用，总共16位。
11. **BGR555**：与RGB555类似，但颜色通道的顺序是蓝、绿、红。
12. **RGB4444**：每个颜色通道使用4位，总共16位。
13. **BGR4444**：与RGB4444类似，但颜色通道的顺序是蓝、绿、红。
14. **RGB332**：每个颜色通道使用3位表示红色，3位表示绿色，2位表示蓝色，总共8位。
15. **BGR332**：与RGB332类似，但颜色通道的顺序是蓝、绿、红。
16. **RGB16**：这是一个通用的术语，可以指任何使用16位来表示RGB颜色的格式，如RGB565、RGB555、RGB4444等。

## 视频编码

### M-JPEG

MJPEG（Motion Joint Photographic Experts Group）是视频压缩格式，其中每一帧图像都分别使用JPEG编码，不使用帧间编码，压缩率通常在20:1-50:1范围内。

JPEG（Joint Photographic Experts Group）是JPEG标准的产物，该标准由国际标准化组织（ISO）制订，是面向连续色调静止图像的一种压缩标准。 JPEG格式是最常用的图像文件格式，后缀名为.jpg或.jpeg。   

### H.264/AVC

H.264，又称为MPEG-4第10部分，高级视频编码（英语：MPEG-4 Part 10, Advanced Video Coding，缩写为MPEG-4 AVC）是一种面向块，基于运动补偿的视频编码标准 。到2014年，它已经成为高精度视频录制、压缩和发布的最常用格式之一。

MPEG - 动态图像专家组（Moving Pictures Experts Group）。该专家组建于1988年，专门负责为CD建立视频和音频标准，而成员都是为视频、音频及系统领域的技术专家。及后，他们成功将声音和影像的记录脱离了传统的模拟方式，建立了ISO/IEC1172压缩编码标准，并制定出MPEG-格式，令视听传播方面进入了数码化时代。

MPEG标准的视频压缩编码技术主要利用了具有运动补偿的帧间压缩编码技术以减小时间冗余度，利用DCT技术以减小图像的空间冗余度，利用熵编码则在信息表示方面减小了统计冗余度。这几种技术的综合运用，大大增强了压缩性能。

### H.265/HEVC

高效率视频编码（High Efficiency Video Coding，简称HEVC），又称为H.265和MPEG-H第2部分，是一种视频压缩标准，获视为是ITU-T H.264/MPEG-4 AVC标准的继任者。2004年开始由ISO/IEC Moving Picture Experts Group（MPEG）和ITU-T Video Coding Experts Group（VCEG）作为ISO/IEC 23008-2 MPEG-H Part 2或称作ITU-T H.265开始制定。第一版的HEVC/H.265视频压缩标准在2013年4月13日获接受为国际电信联盟（ITU-T）的正式标准。

HEVC获认为不仅提升影像质量，同时也能达到H.264/MPEG-4 AVC两倍之压缩率（等同于同样画面质量下比特率减少到了50%），可支持4K清晰度甚至到超高清电视（UHDTV），最高清晰度可达到8192×4320（8K清晰度）。

### H.266/VVC

多功能视频编码（Versatile Video Coding），是最新的视频编码标准，提供了对SDR、HDR和360视频的优化。

### VP9

由Google开发，是一个开源和免版税的视频编码格式，旨在提供比H.264更好的压缩效率。

### AV1

是一个开源的视频编码格式，由联盟开放媒体（AOMedia）开发，旨在提供比VP9更高的压缩效率，适用于4K和8K视频。

### WMV

由微软开发，包括多个版本如WMV 7, WMV 8, WMV 9/VC-1等。

### AVS

中国的音频视频标准，包括AVS/AVS+/AVS2等。

## 音频编码

**PCM (Pulse Code Modulation)**：是一种无压缩的音频编码格式，能够提供高质量的音频输出。

**WAV**：通常基于PCM编码，是一种无损音频格式，常用于存储未压缩的音频数据。

**FLAC (Free Lossless Audio Codec)**：一种无损音频压缩编码格式，提供了与WAV相同的音质但文件更小。

**Opus**：一种开源、免版税的音频编码标准，适用于多种应用场景，包括实时通信和音乐流。

**Speex**：专为语音设计的开源音频编码格式，特别适合用于VoIP和语音通信。

**Dolby Digital (AC-3)**：杜比实验室开发的多声道音频编码格式，广泛用于电影和家庭影院系统。

**ALAC (Apple Lossless Audio Codec)**：苹果开发的无损音频编码格式，用于保持音频文件的原始质量。

### G.711

G.711是一种由国际电信联盟（ITU-T）制定的音频编码方式，又称为ITU-T G.711。

它是国际电信联盟ITU-T定制出来的一套语音压缩标准，它代表了对数PCM（logarithmic pulse-code modulation）抽样标准，主要用于电话。它主要用脉冲编码调制对音频采样，采样率为8k每秒。它利用一个 64Kbps 未压缩通道传输语音讯号。 起压缩率为1：2， 即把16位数据压缩成8位。G.711是主流的波形声音编解码器。

G.711 标准下主要有两种压缩算法。一种是&micro;-law algorithm （又称often u-law, ulaw, mu-law），主要运用于北美和日本；另一种是A-law algorithm，主要运用于欧洲和世界其他地区。其中，后者是特别设计用来方便计算机处理的。

### G.726

G.726，是ITU-T定义的音频编码算法，1990年 CCITT（ITU前身）在G.721和G.723标准的基础上提出，可将64kbps的PCM信号转换为40kbps、32kbps、24kbps、16kbps的ADPCM信号。

### ADPCM

自适应差分脉冲编码调制（Adaptive Differential Pulse Code Modulation）是预测编码的一种，在PCM基础上进行了改进，对实际信号与按其前一些信号而得的预测值间的差值信号进行编码。

话音信号样值的相关性，使差值信号的动态范围较话音样值本身的动态范围大大缩小，用较低码速也能得到足够精确的编码效果，在ADPCM中所用的量化间隔的大小还可按差值信号的统计结果自动适配，达到最佳量化，从而使因量化造成的失真亦最小，ADPCM方式已广泛应用于数字通信、卫星通信、数字话音插空设备及变速率编码器中。

### MP3

 **(MPEG-1 Audio Layer III)**：一种有损压缩的音频编码格式，广泛用于音乐的在线播放和下载。

### AAC

AAC（Advanced Audio Coding），中文名：高级音频编码。出现于1997年，基于MPEG-2的音频编码技术。由Fraunhofer IIS、杜比实验室、AT&T、索尼等公司共同开发，目的是取代MP3格式。

2000年，MPEG-4标准出现后，AAC重新集成了其特性，加入了SBR技术和PS技术，为了区别于传统的MPEG-2 AAC又称为MPEG-4 AAC。

<br/>

# 封装格式

视频封装格式，也称为容器格式，是一种将已编码的视频数据和音频数据打包在一起以便于存储和传输的格式。它不仅包含媒体数据，还可能包括如字幕、章节、元数据等其他信息。

### ES

**原始流 (Elementary Streams)** 是直接从编码器出来的数据流，可以是编码过的视频数据流（H.264,MJPEG 等），音频数据流（AAC），或其他编码数据流的统称。

### TS

**MPEG-TS (Transport Stream)**：常用于广播和流媒体传输，如数字电视和网络流。

### FLV

**FLV(Flash Video)**：广泛用于在线视频流，尽管Flash技术已逐渐被淘汰，但FLV文件格式仍然存在。

### F4V

F4V：与FLV相似，但通常用于更高质量的视频内容，支持H.264视频编码。

### MP4

**MP4 (MPEG-4 Part 14)**：支持多种视频编码和音频编码，是目前最流行的视频容器格式之一，广泛应用于网络视频和移动设备。

### MKV

MKV (Matroska Video)：一个开放源代码和免费的容器格式，支持自由选择的视频和音频编码，且不包含任何版权费用。

### OGG

OGG：一个自由开源的多媒体容器格式，支持多种音频和视频编码。

### WebM

WebM：由Google支持的开放源代码视频容器格式，旨在提供网络友好的视频编码。

### 3GP

3GP：为3G移动设备设计的视频容器格式，常用于手机视频。

### MXF

MXF (Material Exchange Format)：专业视频和音频应用中使用的容器格式，常用于广播行业。

### AVCHD

AVCHD：用于高清视频录像的格式，常用于一些摄像机和高清视频摄影机。

### DVR-MS

DVR-MS：微软开发的用于数字视频录像的格式。

### AVI

AVI (Audio Video Interleave)：由微软开发，是一个较老的容器格式，支持多种编码方式，但文件体积通常较大。

### WMV

WMV (Windows Media Video)：由微软开发，主要用于Windows平台。

### ASF

ASF (Advanced Systems Format)：由微软开发，用于Windows媒体服务。

### MOV

MOV (QuickTime File Format)：由Apple开发，广泛用于视频编辑领域和Apple设备。

### QuickTime

QuickTime：除了是Apple的多媒体框架外，它也是一种视频文件格式。

### RM

RM (RealMedia)：由RealNetworks开发，用于流媒体应用。

<br/>

# 传输协议

### SIP

会话初始协议（Session Initiation Protocol）。用于多方多媒体通信的框架协议，由IETF（互联网工程任务组 - Internet Engineering Task Force）（[IETF Datatracker](https://datatracker.ietf.org/)）制定。[RFC 3261 - SIP: Session Initiation Protocol (ietf.org)](https://datatracker.ietf.org/doc/html/rfc3261)

### SDP

会话描述协议（Session Description Protocol）。SDP旨在描述多媒体会话，用于会话通知、会话邀请和其他形式的多媒体会话发起。[RFC 4566 - SDP: Session Description Protocol (ietf.org)](https://datatracker.ietf.org/doc/html/rfc4566)

### RTP

实时传输协议（Real-time Transport Protocol）。提供一个端到端的网络传输，用于实时数据传输应用，可用于传输语音、视频或模拟数据。[RFC 3550 - RTP: A Transport Protocol for Real-Time Applications (ietf.org)](https://datatracker.ietf.org/doc/html/rfc3550)

### SRTP

安全实时传输协议（Secure Real-Time Transport Protocol），是RTP(实时传输协议)的扩展配置文件。

### RTCP

RTP 控制协议（RTP Control Protocol）。RTCP 提供数据分发质量反馈信息，流控制和拥塞控制。

### RTSP

实时流协议（Real Time Streaming Protocol）。该协议定义了一对多应用程序如何有效地通过IP网络传送多媒体数据。RTSP在体系结构上位于RTP和RTCP之上，服务器端可以自行选择使用TCP或UDP来传送串流内容。

### RTMP

实时消息传输协议（Real Time Messaging Protocol）。该协议基于TCP，是一个协议族，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP是一种设计用来进行实时数据通信的网络协议，主要用来在 Flash/AIR 平台和支持 RTMP 协议的流媒体/交互服务器之间进行音视频和数据通信。

### SRT

安全可靠传输协议（Secure Reliable Transport）。是一种基于UDP协议的开源互联网传输协议，Haivision和Wowza合作成立SRT联盟，管理和支持SRT协议开源应用的组织，这个组织致力于促进视频流解决方案的互通性，以及推动视频产业先驱协作前进，实现低延时网络视频传输。

### WebSocket

是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。[WebSocket - Web API 接口参考 | MDN (mozilla.org)](https://developer.mozilla.org/zh-CN/docs/Web/API/WebSocket)

### [WebRTC](https://webrtc.org/?hl=zh-cn)

网络实时通信（Web Real-Time Communications）。它允许网络应用或者站点，在不借助中间媒介的情况下，建立浏览器之间点对点（Peer-to-Peer）的连接，实现视频流和（或）音频流或者其他任意数据的传输。

借助 WebRTC，您可以为应用添加基于开放标准运行的实时通信功能。它支持在对等设备之间发送视频、语音和通用数据，使开发者能够构建强大的语音和视频通信解决方案。这项技术适用于所有现代浏览器以及所有主要平台的原生客户端。WebRTC 采用的技术是开放网络标准，以常规 JavaScript API 的形式在所有主流浏览器中提供。对于原生客户端（例如 Android 和 iOS 应用），可以使用具备相同功能的库。WebRTC 项目属于[开源项目](https://webrtc.googlesource.com/src/)，受 Apple、Google、Microsoft 和 Mozilla 等公司支持。

### [ONVIF](https://www.onvif.org/)

开放式网络视频接口论坛（Open Network Video Interface Forum）。是一个开放的行业论坛，为基于IP的物理安全产品的有效互操作性提供并促进标准化接口。

### GB28181

国家标准 GB/T 28181《公共安全视频监控联网系统信息传输、交换、控制技术要求》。该标准规定了视频联网系统的联网结构、信令流程、协议接口以及相关安全性要求，适用于公共安全视频联网系统的方案设计、系统检测、验收以及与之相关的设备研发、生产。[GB28181_| 国家标准全文公开系统](https://openstd.samr.gov.cn/bzgk/gb/std_list_type?p.p1=2&p.p2=28181)

### UPnP

通用即插即用（Universal Plug and Play）是由“通用即插即用论坛”（UPnP™ Forum）推广的一套网络协议。该协议的目标是使家庭网络（数据共享、通信和娱乐）和公司网络中的各种设备能够相互无缝连接，并简化相关网络的实现。UPnP通过定义和发布基于开放、因特网通讯网协议标准的UPnP设备控制协议来实现这一目标。

### HLS

（HTTP Live Streaming）是Apple的动态码率自适应技术。主要用于PC和Apple终端的音视频服务。包括一个m3u(8)的索引文件，TS媒体分片文件和key加密串文件。

<br/>

# 常用库

### [FFmpeg](https://ffmpeg.org/)

用于录制、转换和流式传输音频和视频的完整的跨平台解决方案。

### [OpenCV](https://opencv.org/)

开放计算机视觉库（Open Computer Vision Library），是世界上最大的开源计算机视觉库，由非盈利组织开源视觉基金会运营。

# 常用框架

### V4L2

V4L2（Video4Linux2）是Linux操作系统中的一个视频捕获API（应用程序编程接口），它允许应用程序与各种视频设备进行交互，如摄像头、电视调谐器、视频编码器和解码器等。V4L2是Video4Linux的后继版本，提供了一系列改进和扩展的功能，以支持现代视频设备。

以下是V4L2的一些关键特性和概念：

1. **设备节点**：在Linux系统中，视频设备通常通过设备文件暴露给用户空间，如`/dev/video0`、`/dev/video1`等。
2. **I/O方法**：V4L2支持多种I/O方法，包括内存映射I/O、用户空间缓冲区I/O和DMA（直接内存访问）。
3. **缓冲区管理**：V4L2使用缓冲区队列来管理视频数据的捕获和播放。应用程序可以请求一组缓冲区，并在这些缓冲区中交换数据。
4. **格式协商**：V4L2允许应用程序与设备协商视频的格式和属性，如分辨率、像素格式、帧率等。
5. **控制接口**：V4L2提供了一个控制接口，允许应用程序查询和修改设备的各种设置，如亮度、对比度、色调等。
6. **扩展支持**：V4L2支持多种扩展，如VBI（垂直消隐间隔）捕获、Sliced VBI、音频捕获、JPEG压缩等。
7. **兼容性**：V4L2旨在与旧版的Video4Linux兼容，使得旧的驱动和应用程序能够在V4L2框架下运行。
8. **多设备支持**：V4L2能够支持多个视频设备，并且可以同时对它们进行操作。
9. **广播类型**：V4L2支持多种广播类型，包括PAL、SECAM、NTSC等。
10. **驱动程序**：有大量的V4L2兼容驱动程序，支持各种USB摄像头、视频捕获卡和其他视频设备。

V4L2是Linux系统中进行视频捕获和处理的基础，广泛应用于视频监控、视频会议、流媒体服务器、IP摄像头等场景。通过V4L2，开发者可以编写高效的视频捕获应用程序，而无需关心底层硬件的实现细节。

<br/>

# 参考

* [相机成像原理之sensor篇 (baidu.com)](https://baijiahao.baidu.com/s?id=1712342625494240361&wfr=spider&for=pc)
* [MIPI CSI-2接口解析① - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/658133104)
* [Aptina HiSPi与并行传感器的桥接 (latticesemi.com)](https://www.latticesemi.com/zh-CN/Products/DesignSoftwareAndIP/IntellectualProperty/ReferenceDesigns/ReferenceDesigns01/AptinaHiSPitoParallelSensorBridge)
* [关于ES、PES、PS以及TS码流 (360doc.com)](http://www.360doc.com/content/13/0829/15/13084517_310733557.shtml)
* [YUV和RGB_显示器 输入颜色格式-CSDN博客](https://blog.csdn.net/qq_42479394/article/details/116156363)
* [Xiph.org | Vorbis & Theora 编码](https://xiph.org)

